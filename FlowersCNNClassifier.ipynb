{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowersCNNClassifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPopMnG+8pEVh6TK+rPIRjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmoohM/Flower-CNN-Classifier/blob/master/FlowersCNNClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMfIaPV4MqkN",
        "colab_type": "text"
      },
      "source": [
        "Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABHPaQGaKTsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOcBeOGWMmx0",
        "colab_type": "text"
      },
      "source": [
        "Load Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNV5kVvaKujc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "zip_file= tf.keras.utils.get_file(origin=_URL,fname=\"flower_photos.tgz\" , extract= True)\n",
        "base_dir= os.path.join(os.path.dirname(zip_file) , 'flower_photos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgwUuPS2M2zM",
        "colab_type": "text"
      },
      "source": [
        "Classes for the flowers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD6OTmU5MlFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD-Z_re2NU1a",
        "colab_type": "text"
      },
      "source": [
        "Separate images into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIIroPWJM76e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for cl in classes:\n",
        "  img_path = os.path.join(base_dir, cl)\n",
        "  images = glob.glob(img_path + '/*.jpg')\n",
        "  print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  num_train = int(round(len(images)*0.8))\n",
        "  train, val = images[:num_train], images[num_train:]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
        "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
        "    shutil.move(v, os.path.join(base_dir, 'val', cl))\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfjv7WWIPvxR",
        "colab_type": "text"
      },
      "source": [
        "Data Generation and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoqvFIiLP8eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SHAPE=150\n",
        "BATCH_SIZE=100\n",
        "\n",
        "image_gen_train = ImageDataGenerator(rescale = 1./255 ,horizontal_flip= True ,rotation_range= 50 ,zoom_range=0.6 ,width_shift_range=[-0.2,0.2] , height_shift_range=[-0.2,0.2] )\n",
        "train_img_gen = image_gen_train.flow_from_directory(batch_size = BATCH_SIZE ,directory = train_dir ,shuffle=True ,target_size = (IMAGE_SHAPE,IMAGE_SHAPE) ,class_mode='sparse')\n",
        "\n",
        "#Validation image generator\n",
        "image_gen_validate= ImageDataGenerator(rescale=1./255)\n",
        "val_img_gen= image_gen_validate.flow_from_directory(batch_size= BATCH_SIZE ,directory=val_dir ,target_size = (IMAGE_SHAPE,IMAGE_SHAPE) ,class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tErZdCzobOQN",
        "colab_type": "text"
      },
      "source": [
        "Create the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s8qpzjbbQsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMAGE_SHAPE,IMAGE_SHAPE, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3ay7O31djqT",
        "colab_type": "text"
      },
      "source": [
        "Compile the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-QSI_ZLdmpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at8HhbSJdq0o",
        "colab_type": "text"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HmuBWF5dt4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=80\n",
        "\n",
        "history = model.fit(train_img_gen ,steps_per_epoch=int(np.ceil(train_img_gen.n / float(BATCH_SIZE))) ,epochs=epochs ,validation_data=val_img_gen ,validation_steps=int(np.ceil(val_img_gen.n / float(BATCH_SIZE))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDQC4YevgmwO",
        "colab_type": "text"
      },
      "source": [
        "Plot validation and Training Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pApYMStXgtEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}